import abc
import torch.nn
import numpy as np
from sklearn import base
from collections import OrderedDict
from abc import ABC, abstractmethod
from torch.optim.optimizer import Optimizer
from enchanter.engine import modules as modules
from typing import Any, Dict, Tuple, Union, List
from torch.utils.data import DataLoader as DataLoader
from enchanter.callbacks import EarlyStopping as EarlyStopping


class BaseRunner(base.BaseEstimator, ABC, metaclass=abc.ABCMeta):
    model: torch.nn.Module = ...
    optimizer: Optimizer = ...
    experiment: Any = ...
    device: torch.device = ...
    pbar: Any = ...
    scheduler: Any = ...
    early_stop: Union[EarlyStopping, None]

    def __init__(self) -> None:
        self._epochs: int = ...
        self._loaders: Dict[str, DataLoader] = ...
        self._metrics: Dict = ...
        ...
    @abstractmethod
    def train_step(self, batch: Tuple) -> Dict[str, torch.Tensor]: ...
    def train_end(self, outputs: List) -> Dict[str, torch.Tensor]: ...
    def val_step(self, batch: Tuple) -> Dict[str, torch.Tensor]: ...
    def val_end(self, outputs: List) -> Dict[str, torch.Tensor]: ...
    def test_step(self, batch: Tuple) -> Dict[str, torch.Tensor]: ...
    def test_end(self, outputs: List) -> Dict[str, torch.Tensor]: ...
    def train_cycle(self, epoch: int, loader: DataLoader) -> None: ...
    def val_cycle(self, epoch: int, loader: DataLoader) -> None: ...
    def test_cycle(self, loader: DataLoader) -> None: ...
    def train_config(self, epochs: int, *args: Any, **kwargs: Any) -> None: ...
    def log_hyperparams(self, dic: Dict=..., prefix: str=...) -> None: ...
    def initialize(self) -> None: ...
    def run(self, verbose: bool = ...): ...
    def predict(self, x: Union[torch.Tensor, np.ndarray]) -> np.ndarray: ...
    def add_loader(self, mode: str, loader: torch.utils.data.DataLoader): ...
    @property
    def loaders(self): ...
    def fit(self, x: np.ndarray, y: np.ndarray, **kwargs) -> None: ...
    def freeze(self) -> None: ...
    def unfreeze(self) -> None: ...
    def save_checkpoint(self) -> Dict[str, OrderedDict]: ...
    def load_checkpoint(self, checkpoint: Dict[str, OrderedDict]) -> Any: ...
    def save(self, directory: str, epoch: int=...) -> None: ...
    def load(self, filename: str, map_location: str=...) -> Any: ...
